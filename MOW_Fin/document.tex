%%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass{article}
\usepackage{graphicx}
\usepackage{polski}
\usepackage[cp1250]{inputenc}
\usepackage{textcomp}
\usepackage{amssymb,amsmath}
\title{Metody Odkrywania Wiedzy\\Sprawozdanie koñcowe z projektu}
\author{Wojciech Klicki\\Konrad Starzyk}
\begin{document}
\maketitle 

\section{Zadanie} 
Zadanie sk³ada siê z dwóch czêœci : implementacyjnej oraz badawczej. 
Czêœæ implementacyjna polega na implementacji metody dokonuj¹cej 
predykcji w œrodowisku GNU R. Na czêœæ drug¹ sk³ada siê szereg 
testów testuj¹cych skutecznoœæ algorytmu.
\newline
Realizacja zadania polega na wykonaniu poni¿szych etapów:
\begin{itemize}
  \item Postawienie pytañ dotycz¹cych danych wejœciowych oraz algorytmu
  kooperatywnej filtracji, na które odpowiedŸ powinniœmy uzyskaæ przy pomocy Slope-One.
  \item Analiza danych – wybranie kategorii oraz atrybutów, które bêd¹
  analizowane przez nasz algorytm.
  \item Implementacja algorytmu.
  \item Wykonanie eksperymentów, a nastêpnie ocena jakoœci klasyfikatora.
\end{itemize}


\section{Opis algorytmów}
\subsection{Kooperatywna filtracja}
Kooperatywna filtracja polega na przewidywaniu ocen jakie otrzymaj¹
 produkty od poszczególnych u¿ytkowników na podstawie ju¿ ocenionych
  produktów. Zgadniêcie oceny polega na za³o¿eniu pewnego podobieñstwa
   oceny jak¹ wystawi u¿ytkownik do ocen ju¿ wystawionych.
   
\subsection{Technika Slope-One}
Przewidywanie preferencji za pomoc¹ techniki Slope-One opiera siê na za³o¿eniu, ¿e
ocenê u¿ytkownika mo¿na przybli¿yæ za pomoc¹ wzoru \begin{math}{f(x)=x+b}\end{math}, który wyznacza 
œredni¹ ró¿nicê pomiêdzy ocenami dwóch u¿ytkowników którzy dokonali oceny 
tego samego elementu. Jest to oczywiœcie daleko id¹ce uproszczenie – w 
rozwiniêciu tej techniki mo¿na korzystaæ z predyktorów o wzorach \begin{math}{f(x)=ax+b}\end{math}
lub nawet \begin{math}{f(x)=ax^2+bx+c}\end{math}. Jak siê jednak okazuje, nawet
taki predyktor jest w stanie trafnie przewidywaæ preferencje u¿ytkowników. 

Oznaczmy przez \begin{math}v_i\end{math} i \begin{math}w_i\end{math} tablice
ocen dla dwóch ró¿nych u¿ytkowników, gdzie \begin{math}{i=1..n}\end{math} jest indeksem przedmiotu. Wtedy
\begin{math}{v_i-w_i}\end{math} jest ró¿nic¹ ocen tego samego przedmiotu przez dwóch u¿ytkowników. Spróbujmy znaleŸæ wartoœæ która
nalepiej przybli¿a ró¿nicê w ocenach dawanych przez tych u¿ytkowników.\newline
Minimalizuj¹c wyra¿enie:
\begin{math}
\sum_{i}{(v_i+b-w_i)^2}
\end{math}
ze wzglêdu na parametr \begin{math}b\end{math} otrzymujemy
\begin{math}b = \dfrac{\sum_{i}{v_i-w_i}}{n}\end{math}.
\newline \newline
Maj¹c zbiór testowy \begin{math}\kappa\end{math} oraz dowolne dwa oceniane
przedmioty \begin{math}i\end{math} oraz \begin{math}j\end{math}, wraz z ich
ocenami \begin{math}u_i\end{math} oraz \begin{math}u_j\end{math} mo¿emy
okreœliæ œrednie odchylenie przedmiotu \begin{math}i\end{math} wzglêdem
\begin{math}j\end{math} jako:
$$dev_{i,j} = \sum_{u \in S}{\dfrac{u_j-u_i}{|S|}} $$
gdzie jako \begin{math}S\end{math} oznaczymy zbiór ocen które 
zawiera³y obydwa przedmioty.\newline
Bior¹c pod uwagê, ¿e nieznan¹ wartoœæ oceny przedmiotu
\begin{math}j\end{math} mo¿emy przewidywaæ jako \begin{math}u_j =
dev_{i,j}+u_i\end{math}, sensowny predyktor móg³by byæ œredni¹ takich
przewidywañ:
 
$$P(u)_j=\dfrac{1}{|R_j|}\sum_{i\in R_j}(dev_{i,j}+u_i)$$

gdzie \begin{math}R_j\end{math} jest zbiorem wszystkich przedmiotów \begin{math}
i\end{math} które zosta³y ocenione i dla których istnieje wyznaczona wartoœæ
œredniego odchylenia wzglêdem przedmiotu \begin{math}j\end{math} równa
\begin{math}dev_{i,j}\end{math}.
Co wiêcej, jeœli dodatowo mo¿na zaobserwowaæ, ¿e zbiór danych jest gêsty, czyli
¿e prawie ka¿da z par filmów posiada pewn¹ ocenê, to mo¿na przyj¹æ, ¿e
\begin{math}R_j ~= S(u)\end{math}  
A poniewa¿ $$\bar{u}=\sum_{i\in
S(u)}\dfrac{u_j}{card(S(u))}=\sum_{i\in R_j}\dfrac{u_j}{card(R_j)}$$ to mo¿emy
przedefiniowaæ predykcjê P: $$P(u)_j=\bar{u}+\dfrac{1}{|R_j|}\sum_{j\in R_j}(dev_{i,j})$$
Wzór tej postaci jest nieco szybszy do przeliczania (zak³adaj¹c, ¿e
znamy œrednie oceny u¿ytkowników).       

\subsection{Implementacja algorytmu}
Przebieg dzia³ania programu mo¿na podzieliæ na nastêpuj¹ce etapy:
\begin{itemize}
  \item Wybór testu: algorytm normalny/uproszczony/losowy
  \item Wczytanie danych ze zbiorów treningowych
  \item Utworzenie dwuwymiarowej tablicy u¿ytkownik/film, przechowuj¹cej
  oceny dla ka¿dej z kombinacji
  \item Utworzenie macierzy dewiacji, przechowuj¹cej œrednie odchylenia ocen
  miêdzy dwoma filmami
  \item Wczytanie zbioru testowego
  \item Wyznaczenie ocen dla danych znajduj¹cych siê w zbiorze testowym
  \item Porównanie ocen i wyznaczenie œredniego b³êdu absolutnego (MAE)
\end{itemize}
Wiêcej informacji na temat przebiegu dzia³ania programu mo¿na znaleŸæ w
dokumentacji kodu.

\section{Plan eksperymentów}
\subsection{Pytania}
\begin{itemize}
  \item Jaka bêdzie przewidywana ocena danego filmu przez danego
  u¿ytkownika wyznaczona przez algorytm?
  \item Jaka bêdzie trafnoœæ tej oceny?
\end{itemize}

\subsection{Charakterystyka zbiorów danych}
Dane u¿ywane do testów pochodz¹ z serwisu Movielens. Dostêpne s¹ dwa zestawy
danych: pierwszy sk³ada siê z 100,000 ocen 1682 filmów wystawionych przez 943
u¿ytkowników. Drugi zawiera oko³o miliona ocen 3900 filmów wystawionych przez
600 u¿ytkowników. Ka¿dy film zosta³ oceniony w skali od 1 do 5.

Do naszych badañ zostanie wykorzystany pierwszy zbiór zawieraj¹cy 100000
rekordów. Zosta³ on ju¿ wstêpnie podzielony na podzbory : trenuj¹cy (80000
ocen) oraz testowy (20000).

\subsection{Parametry algorytmów których wp³yw na wyniki bêdzie badany}
 
Algorytm nie zawiera parametrów którymi mo¿na sterowaæ jego dzia³aniem. 

\subsection{Sposób oceny jakoœci modeli}
Aby oceniæ trafnoœæ przewidywañ porównamy je z danymi ze zbioru testowego.
Do porównania u¿yjemy miary zwanej Mean Average Error (MAE).

$$MAE=\dfrac{1}{card(X'))}\sum_{u\in
X'}\dfrac{1}{card(S(u))}\sum_{i\in S(u)}|P(u_i)-u_i|$$


Gdzie X' jest zbiorem wszystkich ewaluacji u¿ytkowników, natomiast u zbiorem
ewaluacji u¿ytkownika.
W wyniku otrzymujemy liczbê bêd¹c¹ œredni¹ œrednich ró¿nic pomiêdzy predykcj¹, a
w³aœciw¹ odpowiedzi¹ ze zbioru wszystkich ewaluacji danego u¿ytkownika.
 
\subsection{Testy}
Po implementacji algorytmu pierwszym testem by³o porównanie wyników dzia³ania
dla prostego zbioru danych z modelem matematycznym zbudowanym w arkuszu
kalkulacyjnym.

\begin{center}
\setlength\fboxsep{5pt}  
\setlength\fboxrule{0.0pt}
\fbox{\scalebox{0.5}{\includegraphics{slope-one.png}}} 
\end{center}
 
To pozwoli³o potwierdziæ poprawnoœæ implementacji. Nastêpnym krokiem by³o
uruchomienie algorytmu slope-one dla piêciu zbiorów testowych pochodz¹cych z
archiwów MovieLens. Przed predykcj¹ algorytm budowa³ na podstawie danych
treningowych (ró¿nych dla ka¿dego z piêciu zbiorów) macierz odchyleñ ocen.
Pierwsze piêæ przebiegów zosta³o wykonanych przy u¿yciu nieuproszczonej wersji
algorytmu. Kolejne piêæ, na tych samych danych, zosta³o wykonane algorytmem ze
zoptymalizowanym wzorem predykcji.\\
\\
Wyniki dla algorytmu nieuproszsczonego:\\
MAE dla T1 = 0.2258310\\
MAE dla T2 = 0.2247096\\
MAE dla T3 = 0.2238898\\
MAE dla T4 = 0.2321149\\
MAE dla T5 = 0.2266362\\
\\
Wyniki dla algorytmu uproszczonego:
\\
MAE dla T1 = 0.2353901\\
MAE dla T2 = 0.2348408\\
MAE dla T3 = 0.2312165\\
MAE dla T4 = 0.2387700\\
MAE dla T5 = 0.2366075\\
\\\\
Ostatnim krokiem by³o przeprowadzenie testów dla zbioru losowych
predykcji. Zbiór losowy zosta³ wygenerowany przy u¿yciu programu
napisanego w œrodowisku Java (pos³u¿y³ do tego pakiet java.math). Efektem tego
losowania by³y indeksy w tablic ocen u¿ytkowników. Dziêki temu mo¿na by³o
wygenerowaæ losowo oceny filmów zgodnie z rozk³adem losowym ocen ze
zbioru treningowego. Nastêpnie tak wygenerowane predykcje zosta³y wprowadzone
do algorytmu licz¹cego MAE. W wyniku tego dzia³ania wygenerowane zosta³y nastêpuj¹ce dane: 
\\\\
MAE dla T1 = 0.3105243\\
MAE dla T2 = 0.3094126\\
MAE dla T3 = 0.3062914\\
MAE dla T4 = 0.3078320\\
MAE dla T5 = 0.3085444\\

\subsection{Wnioski}

Z powy¿szych danych liczbowych o b³êdzie MAE mo¿na wywniskowaæ, ¿e nasza
implementacja algorytmu slope-one da³a lepsze wyniki ni¿ losowe zgadywanie
ocen, które zachowywa³o ich rozk³ad. Co wiêcej uzyskaliœmy tak¿e pewne ró¿nice
pomiêdzy implementacj¹ uproszczon¹ a pe³n¹ algorytmu predykcji. Algorytm pe³ny,
zgodnie z przewidywaniami okaza³ siê nieznacznie lepszy.
Testy okaza³y siê niezwykle czasoch³onne. Wynika³o to g³ównie z przyjêtego
sposobu implementacji opartego na pêtlach, które to s¹ niestety bardzo
niewydajnym narzêdziem w obrêbie œrodowiska GNU R.

\end{document}
