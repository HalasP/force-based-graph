\documentclass{article}
\usepackage{graphicx}
\usepackage{polski}
\usepackage[cp1250]{inputenc}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{amssymb,amsmath}
\title{Metod Odkrywania Wiedzy\\Sprawozdanie koñcowe z projektu}

\author{Wojciech Klicki\\Konrad Starzyk}
\begin{document}

\maketitle 
\section{Zadanie} 
Zadanie sk³ada siê z dwóch czêœci : implementacyjnej oraz badawczej. 
Czêœæ implementacyjna polega na implementacji metody dokonuj¹cej 
predykcji w œrodowisku GNU R. Na czêœæ drug¹ sk³ada siê szereg 
testów testuj¹cych skutecznoœæ algorytmu.
\newline
Realizacja zadania polega na wykonaniu poni¿szych etapów:
\begin{itemize}
  \item Postawienie pytañ dotycz¹cych danych wejœciowych oraz algorytmu
  kooperatywnej filtracji, na które odpowiedŸ powinniœmy uzyskaæ przy pomocy Slope-One.
  \item Analiza danych – wybranie kategorii oraz atrybutów, które bêd¹
  analizowane przez nasz algorytm.
  \item Implementacja algorytmu.
  \item Wykonanie eksperymentów, a nastêpnie ocena jakoœci klasyfikatora.
\end{itemize}

\section{Opis algorytmów}
\subsection{Kooperatywna filtracja}
Kooperatywna filtracja polega na przewidywaniu ocen jakie otrzymaj¹
 produkty od poszczególnych u¿ytkowników na podstawie ju¿ ocenionych
  produktów. Zgadniêcie oceny polega na za³o¿eniu pewnego podobieñstwa
   oceny jak¹ wystawi u¿ytkownik do ocen ju¿ wystawionych.
\subsection{Technika Slope-One}
Przewidywanie preferencji za pomoc¹ techniki Slope-One opiera siê na za³o¿eniu, ¿e
ocenê u¿ytkownika mo¿na przybli¿yæ za pomoc¹ wzoru \begin{math}{f(x)=x+b}\end{math}, który wyznacza 
œredni¹ ró¿nicê pomiêdzy ocenami dwóch u¿ytkowników którzy dokonali oceny 
tego samego elementu. Jest to oczywiœcie daleko id¹ce uproszczenie – w 
rozwiniêciu tej techniki mo¿na korzystaæ z predyktorów o wzorach \begin{math}{f(x)=ax+b}\end{math}
lub nawet \begin{math}{f(x)=ax^2+bx+c}\end{math}. Jak siê jednak okazuje, nawet
taki predyktor jest w stanie trafnie przewidywaæ preferencje u¿ytkowników. 

\newline
Oznaczmy przez \begin{math}v_i\end{math} i \begin{math}w_i\end{math} tablice
ocen dla dwóch ró¿nych u¿ytkowników, gdzie \begin{math}{i=1..n}\end{math} jest indeksem przedmiotu. Wtedy
\begin{math}{v_i-w_i}\end{math} jest ró¿nic¹ ocen tego samego przedmiotu przez dwóch u¿ytkowników. Spróbujmy znaleŸæ wartoœæ która
nalepiej przybli¿a ró¿nicê w ocenach dawanych przez tych u¿ytkowników.\newline
Minimalizuj¹c wyra¿enie:
\begin{math}
\sum_{i}{(v_i+b-w_i)^2}
\end{math}
ze wzglêdu na parametr \begin{math}b\end{math} otrzymujemy
\begin{math}b = \dfrac{\sum_{i}{v_i-w_i}}{n}\end{math}.
\newline \newline
Maj¹c zbiór testowy \begin{math}\kappa\end{math} oraz dowolne dwa oceniane
przedmioty \begin{math}i\end{math} oraz \begin{math}j\end{math}, wraz z ich
ocenami \begin{math}u_i\end{math} oraz \begin{math}u_j\end{math} mo¿emy
okreœliæ œrednie odchylenie przedmiotu \begin{math}i\end{math} wzglêdem
\begin{math}j\end{math} jako:
$$dev_{i,j} = \sum_{u \in S}{\dfrac{u_j-u_i}{|S|}} $$
gdzie jako \begin{math}S\end{math} oznaczymy zbiór ocen które 
zawiera³y obydwa przedmioty.\newline
Bior¹c pod uwagê, ¿e nieznan¹ wartoœæ oceny przedmiotu
\begin{math}j\end{math} mo¿emy przewidywaæ jako \begin{math}u_j =
dev_{i,j}+u_i\end{math}, sensowny predyktor móg³by byæ œredni¹ takich
przewidywañ: 
$$P(u)_j=\dfrac{1}{|R_j|}\sum_{i\in R_j}(dev_{i,j}+u_i)$$
gdzie \begin{math}R_j\end{math} jest zbiorem wszystkich przedmiotów \begin{math}
i\end{math} które zosta³y ocenione i dla których istnieje wyznaczona wartoœæ
œredniego odchylenia wzglêdem przedmiotu \begin{math}j\end{math} równa
\begin{math}dev_{i,j}\end{math}.
Co wiêcej, jeœli dodatowo mo¿na zaobserwowaæ, ¿e zbiór danych jest gêsty, czyli
¿e prawie ka¿da z par filmów posiada pewn¹ ocenê, to mo¿na przyj¹æ, ¿e
\begin{math}R_j ~= S(u)\end{math}  
A poniewa¿ \begin{math}\bar{u}=\sum_{i\i S(u)}\dfrac{u_j}{card(S(u))}=\sum_{i\i
R_j}\dfrac{u_j}{card(R_j)}\end{math} to mo¿emy przedefiniowaæ predykcjê P:
$$P(u)_j=\bar{u}+\dfrac{1}{|R_j|}\sum_{i\in R_j}(dev_{i,j})$$
Wzór tej postaci jest du¿o szybszy do przeliczania (zak³adaj¹c, ¿e
znamy œrednie oceny u¿ytkowników).           
\section{Plan eksperymentów}
\subsection{Pytania}
\begin{itemize}
  \item Jaka bêdzie przewidywana ocena danego filmu przez danego
  u¿ytkownika wyznaczona przez algorytm?
  \item Jaka bêdzie trafnoœæ tej oceny?
\end{itemize}

\subsection{Charakterystyka zbiorów danych}
Dane u¿ywane do testów pochodz¹ z serwisu Movielens. Dostêpne s¹ dwa zestawy
danych: pierwszy sk³ada siê z 100,000 ocen 1682 filmów wystawionych przez 943
u¿ytkowników. Drugi zawiera oko³o miliona ocen 3900 filmów wystawionych przez
600 u¿ytkowników. Ka¿dy film zosta³ oceniony w skali od 1 do 5.

Do naszych badañ zostanie wykorzystany pierwszy zbiór zawieraj¹cy 100000
rekordów. Zosta³ on ju¿ wstêpnie podzielony na podzbory : trenuj¹cy (80000
ocen) oraz testowy (20000).

\subsection{Parametry algorytmów których wp³yw na wyniki bêdzie badany}
 
Algorytm nie zawiera parametrów którymi mo¿na sterowaæ jego dzia³aniem. 

\subsection{Sposób oceny jakoœci modeli}
Aby oceniæ trafnoœæ przewidywañ porównamy je z danymi ze zbioru testowego.
Do porównania u¿yjemy miary zwanej Mean Average Error (MAE).

$$MAE=\dfrac{1}{card(X'))}\sum_{u\in
X'}\dfrac{1}{card(S(u))}\sum_{i\in S(u)}|P(u_i)-u_i|$$

Gdzie X' jest zbiorem wszystkich ewaluacji u¿ytkowników, natomiast u zbiorem
ewaluacji u¿ytkownika.
W wyniku otrzymujemy liczbê bêd¹c¹ œredni¹ œrednich ró¿nic pomiêdzy predykcj¹, a
w³aœciw¹ odpowiedzi¹ ze zbioru wszystkich ewaluacji danego u¿ytkownika.
 
\subsection{Testy}
Po implementacji algorytmu pierwszym testem by³o porównanie wyników dzia³ania
dla prostego zbioru danych z modelem matematycznym zbudowanym w arkuszu
kalkulacyjnym.

\begin{center}
\setlength\fboxsep{5pt}  
\setlength\fboxrule{0.0pt}
\fbox{\scalebox{0.5}{\includegraphics{slope-one.png}}} 
\end{center}
 
To pozwoli³o potwierdziæ poprawnoœæ implementacji. Nastêpnym krokiem by³o
uruchomienie algorytmu slope-one dla piêciu zbiorów testowych pochodz¹cych z
archiwów MoveLens. Przed predykcj¹ algorytm budowa³ na podstawie danych
treningowych (ró¿nych dla ka¿dego z piêciu zbiorów) macierz odchyleñ ocen.
Pierwsze piêæ przebiegów zosta³o wykonanych przy u¿yciu nie uproszczonej wersji
algorytmu. Kolejne piêæ, na tych samych danych, zosta³o wykonane algorytmem ze
zoptymalizowanym wzorem predykcji.
